# Perceptron vs Multilayer Perceptron (Step vs Sigmoid)

## Project Overview
This project demonstrates the difference between a Single Layer Perceptron 
using a Step activation function and a Multilayer Perceptron using a Sigmoid 
activation function.

The comparison is done using Python in Google Colab with visualizations and 
prediction analysis.

## Objectives
- Implement Perceptron with Step function
- Implement Multilayer Perceptron with Sigmoid function
- Compare outputs, decision boundaries, and predictions
- Show why Sigmoid performs better than Step function

## Technologies Used
- Python
- NumPy
- Matplotlib
- Google Colab

## Key Observations
- Step function produces binary output and is not differentiable
- Sigmoid function produces smooth probability-based output
- Multilayer Perceptron with Sigmoid gives more accurate predictions
- Visualization clearly shows better learning behavior with Sigmoid

## Conclusion
This project highlights why modern neural networks prefer differentiable 
activation functions like Sigmoid over Step functions.

## Author
Manasa Meesala
